---
title: 'Tutorial'
output:
  rmarkdown::html_vignette:
    toc: false
    toc_depth: 4
    number_sections: false
bibliography: cttb.bib      
vignette: >
  %\VignetteIndexEntry{Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
header-includes:  
    - \newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
    - \def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}
    - \usepackage{tikz}
    - \usetikzlibrary{positioning,shapes.geometric,chains,calc,shapes}
    - \usepackage{lmodern}
    - \usepackage{amssymb,amsmath}
    - \usepackage{ifxetex,ifluatex}
    - \usepackage{adjustbox} % adjust the size of table
    - \usepackage{mathtools}
    - \usepackage{threeparttable}
    - \usepackage{tabularx}
    - \usepackage{rotating}
    - \usepackage{fixltx2e}
    - \usepackage{bbm}
---
<!-- 
  Code to Justify Text
    <style>
    body {
    text-align: justify}
    </style>
-->   
```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```  

In this tutorial, we demonstrate how to use the *CTB* package in *R* for implementing the covariate-tightened trimming bounds method proposed by @samii2023generalizing. This method enables empirical researchers to construct bounds for the local average treatment effect on a sub-population known as the always-responders in experiments or quasi-experiments, when faced with missing outcome or sample selection driven by potentially unobservable factors. 

## Introduction of the method
Consider an experiment with $N$ units. For each unit $i$, we denote the outcome as $Y_i$, the binary treatment status as $D_i$, the binary response indicator as $S_i$, and $P$ pre-treatment covariates as $\mathbf{X}_i = (X_{1i}, X_{2i}, \dots, X_{Pi})$. The outcome $Y_i$ is observed only when $S_i = 1$. The variable $S_i$ reflects whether the unit opts to participate in the experiment or report the outcome, and thus, it may be influenced by the treatment status. Under the potential outcome framework, we have
$$
Y_i = \begin{cases}
Y_i(1), D_i = 1 \\
Y_i(0), D_i = 0,
\end{cases} \text{ and } S_i = \begin{cases}
S_i(1), D_i = 1 \\
S_i(0), D_i = 0.
\end{cases}
$$
For simplicity, we assume that the treatment is randomly assigned with a positive and known probability, hence
$$
\begin{aligned}
& (Y_i(1), Y_i(0), S_i(1), S_i(0)) \perp D_i, \\
& \varepsilon < P(D_i = 1) < 1 - \varepsilon, \text{ with } \varepsilon > 0.
\end{aligned}
$$
Note that we can only estimate the average outcome in either the treatment group or the control group conditional on the event $S_i = 1$. Since $S_i$ is not randomly assigned, the difference-in-means estimator may no longer be unbiased. As depicted in the Directed Acyclic Graph (DAG) below, there may exist an unobservable variable $U_i$ influencing both $S_i$ and $Y_i$. Then, the difference in the average outcome across the two groups captures the influence of both $U_i$ and $D_i$, hence does not estimate the average treatment effect accurately.
```{tikz, echo=FALSE, fig.ext = 'png'}
\begin{tikzpicture}
[scale=0.7,dot/.style={fill,draw,circle,minimum width=1pt},
arrow style/.style={->,line width=1pt, shorten <=2pt,shorten >=2pt },
arrow2 style/.style={->,line width=2pt, shorten <=2pt,shorten >=2pt },]
\node [fill=white, dot, label=above: $S_{i}$] (s) at (3,3) {}; 
\node [fill=white, dot, label=below right: $Y_{i}$] (y) at (6,1) {} edge [arrow2 style] (s);
\node [fill=white, dot, label=below left: $D_{i}$] (d) at (1,1) {} edge [arrow style] (y) edge [arrow2 style] (s);
\node [fill=black, dot, label=above right: $U_{i}$] (u) at (6,3) {} edge [arrow2 style] (y) edge [arrow2 style] (s);
\end{tikzpicture}
```

Conventionally, to mitigate the bias arising from conditioning on $S_i$, researchers often turn to sample selection models [@heckman1979sample] or various imputation methods [@honaker2011amelia; @li2013weighting; @blackwell2017unified; @liu2021latent]. However, these methods generally assume that researchers have access to all variables influencing the selection process, a condition that is often unrealistic and contradicts the core rationale of conducting an experiment. An alternative approach, which does not rely on such comprehensive knowledge, was proposed by @lee2009training. This method involves bounding the average treatment effect for a specific subgroup known as the always-respondersâ€”units whose response indicator remains at $1$ regardless of whether they are under treatment or control conditions. This quantity is formally defined as
$$
\tau(1, 1) = E[\tau_i | S_i(0) = S_i(1) = 1].
$$
It is sometimes referred to as the "intensive margin effect" in economics literature [@staub2014causal; @slough2022phantom]. From a policy standpoint, this particular subgroup represents units for whom the intervention poses minimal concerns about compelling them into an activity they may find undesirable. 

@lee2009training shows that we can bound $\tau(1, 1)$ under a much weaker assumption known as monotonic selection:
$$
S_i(1) \geq S_i(0) \text{ for any unit } i,
$$
which means that the treatment encourages all units to participate in the experiment and report the outcome. Obviously, we can also assume the opposition direction holds. This assumption is implied by all sample selection models but allows us to be agnostic of the actual selection process. When it is satisfied, we can see that $E[Y_{i} | D_i = 0, S_i = 1]$ is the expected outcome under control for 
construct sharp bounds for $\tau(1, 1)$ as follows:
$$
\begin{aligned}
& \tau^L_{TB}(1, 1) = E[Y_{i} | D_i = 1, S_i = 1, Y_i \leq y_{q}] - E[Y_{i} | D_i = 0, S_i = 1], \\
& \tau^U_{TB}(1, 1) = E[Y_{i} | D_i = 1, S_i = 1, Y_i \geq y_{1-q}] - E[Y_{i} | D_i = 0, S_i = 1], \\
& \tau^L_{TB}(1, 1) \leq \tau(1, 1) \leq \tau^U_{TB}(1, 1),
\end{aligned}
$$
where $y_{q}$ is the $q$th-quantile of the observed outcome's conditional distribution in the treatment group. It satisfies the condition $\int_{-\infty}^{y_{q}} dF_{Y|D=1, S=1}(y) = q$, with $F_{Y|D=1, S=1}(\cdot)$ being the distribution function for observed treatment group outcomes.
The quantile $y_{1-q}$ is similarly defined. 

##  Simulated data
We now show how to use the main functions in the package with a simulated experiment (*simData*). The dataset includes $1,000$ units. The treatment is randomly assigned with a probability of $0.5$. For each unit, we have $10$ covariates, $X1$ to $X10$. All the covariates are uniformed distributed on $[0, 1]$. Among them, only one ($X1$) affects both the outcome and the response. In addition, there exists a variable ($U \sim unif[-2, 2]$) that is unobservable to researchers but also affects both the outcome and the response. We describe the DGP with more details in the [paper](https://papers.ssrn.com/abstract=3555463). 
```{r data, message = FALSE, warning = FALSE}
set.seed(1234)
library(CTB)
library(grf)
data(simData)

N <- nrow(simData)

yrange <- range(c(simData$Y0, simData$Y1))
xrange <- range(simData$X2)

plot(Y1 ~ X2, simData,
     pch=19,
     col="black",
     ylim=yrange, xlim=xrange,
     main="Potential outcomes",
     xlab=expression('X'[1]), ylab="Y", 
     cex.lab=2, cex.axis=2)
points(Y0 ~ X2, simData,
       pch=21,
       col="black",
       bg="white")

plot(subset(simData, D==1&S==1)$X2,
     subset(simData, D==1&S==1)$Y,
     ylim=yrange, xlim=xrange,
     pch=19,
     col="black",
     main="Experimental outcomes \n (red means attrited)",
     xlab=expression('X'[1]), ylab="Y", 
     cex.lab=2, cex.axis=2)
points(subset(simData, D==0&S==0)$X2,
       subset(simData, D==0&S==0)$Y,
       ylim=yrange, xlim=xrange,
       pch=19,
       col="red")
points(subset(simData, D==1&S==0)$X2,
       subset(simData, D==1&S==0)$Y,
       ylim=yrange, xlim=xrange,
       pch=19,
       col="red")
points(subset(simData, D==0&S==1)$X2,
       subset(simData, D==0&S==1)$Y,
       pch=21,
       col="black",
       bg="white")

plot(subset(simData, D==1&S==1)$X2,
     subset(simData, D==1&S==1)$Y,
     ylim=yrange, xlim=xrange,
     pch=19,
     col="black",
     main="Observed outcomes",
     xlab=expression('X'[1]), ylab="Y", 
     cex.lab=2, cex.axis=2)
points(subset(simData, D==0)$X2,
       subset(simData, D==0)$Y,
       pch=21,
       col="black",
       bg="white")
```

Plots above show
```{r estimand, message = FALSE, warning = FALSE}
# generate the data with missing outcome values
dat <- simData
dat[dat$S == 0, "Y"] <- NA

cat("The ATE equals ", mean(simData$Y1 - simData$Y0), "\n")
cat("The ATE for always-responders equals ", mean(true_parameters$Ete_ar), "\n")
cat("The difference-in-means estimator generates an estimate of ", mean(dat$Y[dat$D == 1 & dat$S == 1]) - mean(dat$Y[dat$D == 0 & dat$S == 1]), "\n")
```

## Covariate-tightened trimming bounds
**CTB** allows users to estimate
We first estimate the aggregated bounds and the classic Lee bounds.


### Aggregated bounds
**Estimation.** We estimate the average treatment effect on the treated (ATT) using the following information: the outcome variable $Y$, binary treatment variable $D$, two observed covariates $X_{1}$ and $X_{2}$, and the unit and time indicators $id$ and $time$, respectively. The first variable on the right hand side of the formula is the treatment indicator $D$; the rest of the right-hand-side variables serve as controls. The `index` option specifies the unit and time indicators. The `force` option ("none", "unit", "time", and "two-way") specifies the additive component(s) of the fixed effects included in the model. 
The default option is "two-way" (including both unit and time fixed effects). 
```{r agg, message = FALSE, warning = FALSE}
result <- CTB(data = dat, seed = NULL, Y = "Y", D = "D", S = "S", X = c(names(dat)[c(2:12)]), W = NULL, Pscore = "Ps", cv_fold = 5, aggBounds = 1, cBounds = 0, X_moderator = NULL, direction = NULL, cond.mono = FALSE)

tau_l_est_avg <- result[["tau_l_est_avg"]]
tau_u_est_avg <- result[["tau_u_est_avg"]]
se_tau_l_est_avg <- result[["se_tau_l_est_avg"]]
se_tau_u_est_avg <- result[["se_tau_u_est_avg"]]
  
tau_l_est_lee <- result[["tau_l_est_lee"]]
tau_u_est_lee <- result[["tau_u_est_lee"]]
se_tau_l_est_lee <- result[["se_tau_l_est_lee"]]
se_tau_u_est_lee <- result[["se_tau_u_est_lee"]]
```


**Uncertainty estimates.** 

**Result summary.** Users can use the **print** function to take a look at a summary of the estimation results or retrieve relevant statistics by directly accessing the fect object. 
Specifically, `est.avg` and `est.avg.unit` show the ATT averaged over all periods -- the former weights each treated observation equally while the latter weights each treated unit equally. 
`est.beta` reports the coefficients of the time-varying covariates. `est.att` reports the average treatment effect on the treated (ATT) by period. Treatment effect estimates from each bootstrap run is stored in `eff.boot`, an array whose dimension = (#time periods * #treated * #bootstrap runs).


### Conditional bounds
```{r cond, message = FALSE, warning = FALSE}
X <- c(names(dat)[c(2:12)])
X_avg <- apply(dat[, X[-2]], 2, mean)
Xm_evals <- quantile(dat[, "X2"], seq(0.05, 0.95, 0.05))
X_moderator <- matrix(rep(X_avg, length(Xm_evals)), length(X_avg), length(Xm_evals))
X_moderator <- rbind(X_moderator, Xm_evals)
X_moderator <- t(X_moderator)
X_moderator <- cbind(X_moderator[, 1], X_moderator[, 11], X_moderator[, 2:10])

# result <- CTB(data = dat, seed = NULL, Y = "Y", D = "D", S = "S", X = c(names(dat)[c(2:12)]), W = NULL, Pscore = "Ps", cv_fold = 5, aggBounds = 1, cBounds = 1, X_moderator = X_moderator, direction = NULL, cond.mono = TRUE)
# 
# tau_l_m_avg <- result[["tau_l_m_avg"]]
# tau_u_m_avg <- result[["tau_u_m_avg"]]
# se_tau_l_m_avg <- result[["se_tau_l_m_avg"]]
# se_tau_u_m_avg <- result[["se_tau_u_m_avg"]]
```


### Lee bounds


---

# Reference
